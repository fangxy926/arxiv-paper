<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>医疗AI学术进展 | 2026-02-19</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --color-bg: #fafafa;
            --color-surface: #ffffff;
            --color-border: #e5e7eb;
            --color-border-light: #f3f4f6;
            --color-text: #111827;
            --color-text-secondary: #4b5563;
            --color-text-muted: #6b7280;
            --color-accent: #1e40af;
            --color-accent-light: #dbeafe;
            --font-serif: 'Crimson Pro', Georgia, 'Times New Roman', serif;
            --font-sans: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: var(--font-sans);
            background: var(--color-bg);
            color: var(--color-text);
            line-height: 1.6;
            font-size: 17px;
        }

        /* Header */
        .header {
            background: var(--color-surface);
            border-bottom: 1px solid var(--color-border);
            padding: 0;
        }

        .header-top {
            max-width: 1400px;
            margin: 0 auto;
            padding: 16px 24px;
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            gap: 24px;
        }

        .header-brand {
            display: flex;
            align-items: center;
            gap: 16px;
        }

        .header-logo {
            width: 48px;
            height: 48px;
            background: var(--color-accent);
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-family: var(--font-serif);
            font-size: 24px;
            font-weight: 700;
        }

        .header-title-group {}

        .header-title {
            font-family: var(--font-serif);
            font-size: 26px;
            font-weight: 700;
            color: var(--color-text);
            letter-spacing: -0.02em;
        }

        .header-subtitle {
            font-size: 14px;
            color: var(--color-text-muted);
            margin-top: 4px;
        }

        .header-meta {
            text-align: right;
        }

        .header-date {
            font-size: 14px;
            font-weight: 600;
            color: var(--color-text-secondary);
            font-family: var(--font-serif);
            font-style: italic;
        }

        .header-range {
            font-size: 13px;
            color: var(--color-text-muted);
            margin-top: 4px;
        }

        .header-total {
            font-size: 32px;
            font-weight: 700;
            color: var(--color-accent);
            margin-top: 8px;
        }

        .header-total-label {
            font-size: 12px;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        /* Navigation Bar */
        .nav-bar {
            background: var(--color-surface);
            border-bottom: 1px solid var(--color-border);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .nav-content {
            max-width: 1400px;
            margin: 0 auto;
            padding: 0 24px;
            display: flex;
            gap: 4px;
            overflow-x: auto;
        }

        .nav-item {
            padding: 12px 16px;
            font-size: 14px;
            font-weight: 500;
            color: var(--color-text-secondary);
            cursor: pointer;
            border: none;
            background: none;
            border-bottom: 2px solid transparent;
            white-space: nowrap;
            transition: all 0.15s;
        }

        .nav-item:hover {
            color: var(--color-text);
            background: var(--color-border-light);
        }

        .nav-item.active {
            color: var(--color-accent);
            border-bottom-color: var(--color-accent);
            font-weight: 600;
        }

        /* Main Content */
        .main {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px 24px 40px;
        }

        /* Stats Panel */
        .stats-panel {
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            border-radius: 8px;
            padding: 16px 20px;
            margin-bottom: 20px;
        }

        .stats-title {
            font-size: 12px;
            font-weight: 600;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 12px;
        }

        .stats-grid {
            display: flex;
            flex-wrap: wrap;
            gap: 12px 24px;
        }

        .stat-item {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 6px 12px;
            border-radius: 4px;
            cursor: pointer;
            transition: background 0.15s;
        }

        .stat-item:hover {
            background: var(--color-border-light);
        }

        .stat-item.active {
            background: var(--color-accent-light);
        }

        .stat-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
        }

        .stat-name {
            font-size: 13px;
            color: var(--color-text-secondary);
        }

        .stat-item.active .stat-name {
            color: var(--color-accent);
            font-weight: 600;
        }

        .stat-count {
            font-size: 13px;
            font-weight: 600;
            color: var(--color-text);
            background: var(--color-border-light);
            padding: 2px 8px;
            border-radius: 12px;
            min-width: 24px;
            text-align: center;
        }

        .stat-item.active .stat-count {
            background: var(--color-accent);
            color: white;
        }

        /* Section */
        .section {
            margin-bottom: 24px;
        }

        .section-header {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 12px 16px;
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            border-left-width: 4px;
            border-radius: 0 8px 8px 0;
            margin-bottom: 12px;
        }

        .section-icon {
            font-size: 18px;
        }

        .section-title {
            font-family: var(--font-serif);
            font-size: 18px;
            font-weight: 700;
        }

        .section-count {
            margin-left: auto;
            font-size: 13px;
            color: var(--color-text-muted);
            font-weight: 500;
        }

        /* Papers Grid */
        .papers-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 12px;
        }

        @media (max-width: 1100px) {
            .papers-grid { grid-template-columns: 1fr; }
        }

        /* Paper Card */
        .paper-card {
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            border-left-width: 3px;
            border-radius: 0 6px 6px 0;
            overflow: hidden;
            transition: box-shadow 0.15s, border-color 0.15s;
        }

        .paper-card:hover {
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
            border-color: #d1d5db;
        }

        .paper-header {
            padding: 14px 16px 10px;
            border-bottom: 1px solid var(--color-border-light);
        }

        .paper-category {
            font-size: 11px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 8px;
        }

        .paper-title {
            font-family: var(--font-serif);
            font-size: 17px;
            font-weight: 600;
            line-height: 1.4;
            color: var(--color-text);
        }

        .paper-title a {
            color: inherit;
            text-decoration: none;
        }

        .paper-title a:hover {
            color: var(--color-accent);
            text-decoration: underline;
        }

        .paper-meta {
            display: flex;
            gap: 12px;
            padding: 8px 16px;
            font-size: 12px;
            color: var(--color-text-muted);
            border-bottom: 1px solid var(--color-border-light);
            background: #fafafa;
        }

        .paper-meta-item {
            display: flex;
            align-items: center;
            gap: 4px;
        }

        .paper-body {
            padding: 12px 16px;
        }

        .paper-summary {
            font-size: 16px;
            line-height: 1.7;
            color: var(--color-text-secondary);
            margin-bottom: 12px;
        }

        .paper-summary::before {
            content: '';
            display: inline-block;
            width: 3px;
            height: 14px;
            background: var(--color-accent);
            margin-right: 8px;
            vertical-align: middle;
        }

        /* Abstract */
        .abstract-section {
            margin-top: 12px;
        }

        .abstract-toggle {
            width: 100%;
            padding: 8px 0;
            background: none;
            border: none;
            font-size: 12px;
            font-weight: 500;
            color: var(--color-accent);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: space-between;
            transition: color 0.15s;
        }

        .abstract-toggle:hover {
            color: #1e3a8a;
        }

        .abstract-toggle-icon {
            transition: transform 0.2s;
        }

        .abstract-toggle.expanded .abstract-toggle-icon {
            transform: rotate(180deg);
        }

        .abstract-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }

        .abstract-content.expanded {
            max-height: 2000px;
        }

        .abstract-inner {
            padding: 12px 0 4px;
            border-top: 1px dashed var(--color-border);
            margin-top: 8px;
        }

        .abstract-block {
            margin-bottom: 12px;
        }

        .abstract-label {
            font-size: 11px;
            font-weight: 600;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.03em;
            margin-bottom: 6px;
        }

        .abstract-text {
            font-size: 15px;
            line-height: 1.7;
            color: var(--color-text-secondary);
        }

        /* Authors & Keywords */
        .paper-footer {
            padding: 10px 16px;
            background: #fafafa;
            border-top: 1px solid var(--color-border-light);
        }

        .paper-authors {
            font-size: 14px;
            color: var(--color-text-secondary);
            margin-bottom: 10px;
            line-height: 1.5;
        }

        .author {
            font-weight: 500;
        }

        .paper-keywords {
            display: flex;
            flex-wrap: wrap;
            gap: 6px;
        }

        .keyword {
            font-size: 11px;
            color: var(--color-accent);
            background: var(--color-accent-light);
            padding: 3px 10px;
            border-radius: 3px;
            font-weight: 500;
        }

        /* Paper Actions */
        .paper-actions {
            display: flex;
            gap: 8px;
            padding: 10px 16px;
            border-top: 1px solid var(--color-border-light);
        }

        .btn {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 8px 16px;
            font-size: 13px;
            font-weight: 500;
            text-decoration: none;
            border-radius: 4px;
            transition: all 0.15s;
            cursor: pointer;
            border: none;
        }

        .btn-primary {
            background: var(--color-accent);
            color: white;
        }

        .btn-primary:hover {
            background: #1e3a8a;
        }

        .btn-secondary {
            background: white;
            color: var(--color-text-secondary);
            border: 1px solid var(--color-border);
        }

        .btn-secondary:hover {
            background: var(--color-border-light);
            color: var(--color-text);
        }

        /* Footer */
        .footer {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px 24px;
            border-top: 1px solid var(--color-border);
            text-align: center;
        }

        .footer-text {
            font-size: 12px;
            color: var(--color-text-muted);
        }

        /* Hidden state */
        .hidden { display: none !important; }

        /* Responsive */
        @media (max-width: 768px) {
            .header-top {
                flex-direction: column;
                padding: 20px;
                gap: 20px;
            }
            .header-meta { text-align: left; }
            .nav-content { padding: 0 20px; }
            .main { padding: 20px; }
            .papers-grid { grid-template-columns: 1fr; }
        }


        .section-header.医疗大模型 { border-left-color: #1e40af; }
        .section-header.医疗大模型 .section-icon { color: #1e40af; }
        .paper-card[data-category="医疗大模型"] { border-left-color: #1e40af; }
        .paper-card[data-category="医疗大模型"] .paper-category { color: #1e40af; }
        .stat-item[data-filter="医疗大模型"].active .stat-dot { box-shadow: 0 0 0 3px #1e40af30; }

        .section-header.医疗数据集 { border-left-color: #047857; }
        .section-header.医疗数据集 .section-icon { color: #047857; }
        .paper-card[data-category="医疗数据集"] { border-left-color: #047857; }
        .paper-card[data-category="医疗数据集"] .paper-category { color: #047857; }
        .stat-item[data-filter="医疗数据集"].active .stat-dot { box-shadow: 0 0 0 3px #04785730; }

        .section-header.医疗智能体 { border-left-color: #7c3aed; }
        .section-header.医疗智能体 .section-icon { color: #7c3aed; }
        .paper-card[data-category="医疗智能体"] { border-left-color: #7c3aed; }
        .paper-card[data-category="医疗智能体"] .paper-category { color: #7c3aed; }
        .stat-item[data-filter="医疗智能体"].active .stat-dot { box-shadow: 0 0 0 3px #7c3aed30; }

    </style>
</head>
<body>
    <header class="header">
        <div class="header-top">
            <div class="header-brand">
                <div class="header-logo">arXiv</div>
                <div class="header-title-group">
                    <h1 class="header-title">医疗AI学术进展周报</h1>
                    <p class="header-subtitle">自动文献综述与前沿追踪</p>
                </div>
            </div>
            <div class="header-meta">
                <div class="header-date">February 20, 2026</div>
                <div class="header-range">2026-02-19 — 2026-02-19</div>
                <div class="header-total">8</div>
                <div class="header-total-label">论文</div>
            </div>
        </div>
    </header>

    <main class="main">
        <div class="stats-panel">
            <div class="stats-title">按研究领域筛选</div>
            <div class="stats-grid">
                <div class="stat-item active" data-filter="all">
                    <span class="stat-dot" style="background: var(--color-accent);"></span>
                    <span class="stat-name">全部主题</span>
                    <span class="stat-count">8</span>
                </div>
                <div class="stat-item" data-filter="医疗大模型">
                    <span class="stat-dot" style="background: #1e40af;"></span>
                    <span class="stat-name">医疗大模型</span>
                    <span class="stat-count">5</span>
                </div>
                <div class="stat-item" data-filter="医疗数据集">
                    <span class="stat-dot" style="background: #047857;"></span>
                    <span class="stat-name">医疗数据集</span>
                    <span class="stat-count">3</span>
                </div>
                <div class="stat-item" data-filter="医疗智能体">
                    <span class="stat-dot" style="background: #7c3aed;"></span>
                    <span class="stat-name">医疗智能体</span>
                    <span class="stat-count">0</span>
                </div>
            </div>
        </div>

        <section class="section">
            <div class="section-header 医疗大模型">
                <span class="section-icon" style="color: #1e40af;">◆</span>
                <h2 class="section-title">医疗大模型</h2>
                <span class="section-count">5 篇论文</span>
            </div>
            <div class="papers-grid">

        <article class="paper-card" data-category="医疗大模型">
            <div class="paper-header">
                <div class="paper-category">医疗大模型 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17646v1" target="_blank">Multi-Round Human-AI Collaboration with User-Specified Requirements</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17646v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文提出一个以人为本的多轮人机协作框架，通过用户定义的反事实伤害和互补性原则来确保AI提升决策质量，并设计了具有有限样本保证的在线算法来执行这些约束。在医疗诊断和图像推理任务上的实验表明，该框架能有效控制违规率，并通过调整约束可预测地影响人的决策准确性。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">随着人类在高风险决策中日益依赖多轮对话式AI，需要原则性框架来确保此类交互可靠地提升决策质量。我们采用以人为本的视角，遵循两个原则：反事实伤害（counterfactual harm），确保AI不削弱人类优势；以及互补性（complementarity），确保AI在人类易出错处增加价值。我们通过用户定义规则（user-defined rules）形式化这些概念，允许用户为其特定任务精确指定伤害和互补性的含义。随后，我们引入一种在线的、无分布（distribution-free）算法，该算法具有有限样本保证（finite sample guarantees），可在协作动态中强制执行用户指定的约束。我们在两种交互设置中评估了我们的框架：在医疗诊断任务上的LLM模拟协作，以及在图像推理任务上的人类众包研究。结果表明，即使在非平稳的交互动态下，我们的在线程序也能维持规定的反事实伤害和互补性违规率。此外，收紧或放松这些约束会导致下游人类准确率产生可预测的变化，证实了这两个原则可作为实际杠杆，引导多轮协作走向更好的决策质量，而无需对或约束人类行为进行建模。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">As humans increasingly rely on multiround conversational AI for high stakes decisions, principled frameworks are needed to ensure such interactions reliably improve decision quality. We adopt a human centric view governed by two principles: counterfactual harm, ensuring the AI does not undermine human strengths, and complementarity, ensuring it adds value where the human is prone to err. We formalize these concepts via user defined rules, allowing users to specify exactly what harm and complementarity mean for their specific task. We then introduce an online, distribution free algorithm with finite sample guarantees that enforces the user-specified constraints over the collaboration dynamics. We evaluate our framework across two interactive settings: LLM simulated collaboration on a medical diagnostic task and a human crowdsourcing study on a pictorial reasoning task. We show that our online procedure maintains prescribed counterfactual harm and complementarity violation rates even under nonstationary interaction dynamics. Moreover, tightening or loosening these constraints produces predictable shifts in downstream human accuracy, confirming that the two principles serve as practical levers for steering multi-round collaboration toward better decision quality without the need to model or constrain human behavior.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Noorani S</span>, <span class="author">Kiyani S</span>, <span class="author">Hassani H</span>, <span class="author">Pappas G</span></div>
                <div class="paper-keywords"><span class="keyword">人机协作</span><span class="keyword">反事实伤害</span><span class="keyword">互补性</span><span class="keyword">用户定义规则</span><span class="keyword">在线算法</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17646v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17646v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>

        <article class="paper-card" data-category="医疗大模型">
            <div class="paper-header">
                <div class="paper-category">医疗大模型 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17566v1" target="_blank">A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17566v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文提出一种基于联邦学习的混合集成模型，结合SWIN Transformer与多种CNN模型（如DenseNet201），利用胸部X光片进行COVID-19和肺炎的诊断。该方案旨在通过分布式学习保障数据安全与隐私，并借助实时持续学习提升疾病诊断与严重性预测的准确性。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">计算能力的显著进步为人工智能（AI）在医疗保健和医学科学的不同应用创造了巨大机会。一种基于联邦学习（Federated Learning）的混合集成方法，用于肺部疾病诊断，结合了SWIN Transformer和CNN（卷积神经网络）的前沿技术。由于医学专家和医院将拥有共享数据空间，基于这些数据，借助人工智能和联邦学习的集成，我们可以引入一个安全、分布式的医疗数据处理系统，并创建一个高效可靠的系统。所提出的混合模型能够基于X射线报告检测COVID-19和肺炎。我们将使用Tensorflow和Keras提供的最新可用技术，以及微软开发的Vision Transformer，这有助于对抗这场需要全世界共同应对的疫情。我们专注于使用最新的CNN模型（DenseNet201, Inception V3, VGG 19）和Transformer模型SWIN Transformer来构建我们的混合模型，旨在为医疗领域的医生提供一个可靠的辅助解决方案。在本研究中，我们将讨论基于联邦学习的混合AI模型如何通过实时持续学习（real-time continual learning）方法提高疾病诊断和患者严重性预测的准确性，以及联邦学习的集成如何确保混合模型的安全性和信息的真实性。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the combination of cutting-edge technology of AI and Federated Learning. Since, medi- cal specialists and hospitals will have shared data space, based on that data, with the help of Artificial Intelligence and integration of federated learning, we can introduce a secure and distributed system for medical data processing and create an efficient and reliable system. The proposed hybrid model enables the detection of COVID-19 and Pneumonia based on x-ray reports. We will use advanced and the latest available tech- nology offered by Tensorflow and Keras along with Microsoft-developed Vision Transformer, that can help to fight against the pandemic that the world has to fight together as a united. We focused on using the latest available CNN models (DenseNet201, Inception V3, VGG 19) and the Transformer model SWIN Transformer in order to prepare our hy- brid model that can provide a reliable solution as a helping hand for the physician in the medical field. In this research, we will discuss how the Federated learning-based Hybrid AI model can improve the accuracy of disease diagnosis and severity prediction of a patient using the real-time continual learning approach and how the integration of federated learn- ing can ensure hybrid model security and keep the authenticity of the information.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Chowdhury AH</span>, <span class="author">Islam MF</span>, <span class="author">Riad MRA</span>, <span class="author">Hashem FB</span>, <span class="author">Reza MT</span>, <span class="author">Alam MGR</span></div>
                <div class="paper-keywords"><span class="keyword">联邦学习</span><span class="keyword">集成学习</span><span class="keyword">医学影像诊断</span><span class="keyword">SWIN Transformer</span><span class="keyword">卷积神经网络</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17566v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17566v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>

        <article class="paper-card" data-category="医疗大模型">
            <div class="paper-header">
                <div class="paper-category">医疗大模型 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17513v1" target="_blank">Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17513v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文通过构建新的产科病历数据集，系统评估了基于Transformer的监督模型与零样本大语言模型在临床文本段落分割任务上的表现。研究发现，监督模型在域内表现良好但跨域性能下降，而经过幻觉校正的零样本模型展现出更强的跨域鲁棒性，为医疗NLP在未充分研究领域的应用提供了新方向。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">临床自由文本笔记包含重要的患者信息。它们被组织成带标签的段落；识别这些段落已被证明有助于临床决策支持和下游NLP任务。在本文中，我们通过三个关键贡献推进临床段落分割研究。首先，我们整理了一个新的去标识化、带段落标签的产科笔记数据集，以补充如MIMIC-III等公共语料库所覆盖的医学领域，现有大多数分割方法都在此类语料上训练。其次，我们在精心整理的MIMIC-III子集（域内）和新产科数据集（域外）上，系统评估了基于Transformer的监督模型用于段落分割的性能。第三，我们首次对用于医学段落分割的监督模型与零样本大语言模型进行了直接比较。我们的结果表明，虽然监督模型在域内表现强劲，但其在域外的性能显著下降。相比之下，一旦校正了幻觉生成的段落标题，零样本模型展现出强大的域外适应能力。这些发现强调了开发特定领域临床资源的重要性，并凸显了零样本分割作为一个有前景的方向，可将医疗NLP应用于已充分研究的语料库之外，前提是幻觉得到适当管理。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">Clinical free-text notes contain vital patient information. They are structured into labelled sections; recognizing these sections has been shown to support clinical decision-making and downstream NLP tasks. In this paper, we advance clinical section segmentation through three key contributions. First, we curate a new de-identified, section-labeled obstetrics notes dataset, to supplement the medical domains covered in public corpora such as MIMIC-III, on which most existing segmentation approaches are trained. Second, we systematically evaluate transformer-based supervised models for section segmentation on a curated subset of MIMIC-III (in-domain), and on the new obstetrics dataset (out-of-domain). Third, we conduct the first head-to-head comparison of supervised models for medical section segmentation with zero-shot large language models. Our results show that while supervised models perform strongly in-domain, their performance drops substantially out-of-domain. In contrast, zero-shot models demonstrate robust out-of-domain adaptability once hallucinated section headers are corrected. These findings underscore the importance of developing domain-specific clinical resources and highlight zero-shot segmentation as a promising direction for applying healthcare NLP beyond well-studied corpora, as long as hallucinations are appropriately managed.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Karacan B</span>, <span class="author">Eugenio BD</span>, <span class="author">Thornton P</span></div>
                <div class="paper-keywords"><span class="keyword">临床文本分割</span><span class="keyword">领域适应</span><span class="keyword">零样本学习</span><span class="keyword">医学自然语言处理</span><span class="keyword">幻觉校正</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17513v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17513v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>

        <article class="paper-card" data-category="医疗大模型">
            <div class="paper-header">
                <div class="paper-category">医疗大模型 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17535v1" target="_blank">LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17535v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文提出LATA方法，一种无需训练和标签的转导适应技术，用于改进医学视觉语言模型在域偏移下的保形不确定性校准。它通过图平滑和新的评分函数，在保证覆盖率的同时，有效减小预测集大小和类别覆盖差异，且计算高效。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">医学视觉语言模型（Medical vision-language models, VLMs）是医学影像的强大零样本识别器，但其在域偏移下的可靠性依赖于有保证的校准不确定性。分割保形预测（Split conformal prediction, SCP）提供了有限样本覆盖率，但预测集通常变得很大（效率低）且类别覆盖率不平衡——类别条件覆盖差距（class-conditioned coverage gap, CCV）高，尤其是在少样本、不平衡的情况下；此外，简单地适应校准标签会破坏可交换性并使保证失效。我们提出LATA（Laplacian-Assisted Transductive Adaptation），这是一种无需训练和标签的改进方法，它通过在图像-图像k近邻图上使用少量CCCP平均场更新来平滑零样本概率，从而在联合校准和测试池上操作，并通过确定性变换保留SCP有效性。我们进一步引入一种故障感知（failure-aware）保形评分，将其插入视觉语言不确定性（vision-language uncertainty, ViLU）框架，提供实例级难度和标签合理性，以在固定覆盖率下提高预测集效率和类别平衡。LATA是黑盒的（无需更新VLM）、计算轻量的（窗口化转导，无反向传播），并包含一个可选先验旋钮，可以严格在无标签模式下运行，或者如果需要，可以使用一次校准边缘信息以标签知情变体运行。在三个医学VLM和九个下游任务中，LATA持续减小集合大小和CCV，同时匹配或收紧目标覆盖率，优于先前的转导基线，并缩小了与使用标签方法的差距，同时计算量少得多。全面的消融实验和定性分析表明，LATA在不损害可交换性的情况下锐化了零样本预测。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become large (low efficiency) and class-wise coverage unbalanced-high class-conditioned coverage gap (CCV), especially in few-shot, imbalanced regimes; moreover, naively adapting to calibration labels breaks exchangeability and voids guarantees. We propose \texttt{\textbf{LATA}} (Laplacian-Assisted Transductive Adaptation), a \textit{training- and label-free} refinement that operates on the joint calibration and test pool by smoothing zero-shot probabilities over an image-image k-NN graph using a small number of CCCP mean-field updates, preserving SCP validity via a deterministic transform. We further introduce a \textit{failure-aware} conformal score that plugs into the vision-language uncertainty (ViLU) framework, providing instance-level difficulty and label plausibility to improve prediction set efficiency and class-wise balance at fixed coverage. \texttt{\textbf{LATA}} is black-box (no VLM updates), compute-light (windowed transduction, no backprop), and includes an optional prior knob that can run strictly label-free or, if desired, in a label-informed variant using calibration marginals once. Across \textbf{three} medical VLMs and \textbf{nine} downstream tasks, \texttt{\textbf{LATA}} consistently reduces set size and CCV while matching or tightening target coverage, outperforming prior transductive baselines and narrowing the gap to label-using methods, while using far less compute. Comprehensive ablations and qualitative analyses show that \texttt{\textbf{LATA}} sharpens zero-shot predictions without compromising exchangeability.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Bozorgtabar B</span>, <span class="author">Mahapatra D</span>, <span class="author">Roy S</span>, <span class="author">Naseer M</span>, <span class="author">Razzak I</span>, <span class="author">Ge Z</span></div>
                <div class="paper-keywords"><span class="keyword">医学视觉语言模型</span><span class="keyword">保形预测</span><span class="keyword">域适应</span><span class="keyword">不确定性校准</span><span class="keyword">转导推理</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17535v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17535v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>

        <article class="paper-card" data-category="医疗大模型">
            <div class="paper-header">
                <div class="paper-category">医疗大模型 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17475v1" target="_blank">Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17475v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文系统评估了约十亿参数的小型大语言模型在意大利语医学NLP任务上的表现。通过比较少样本提示、约束解码、监督微调和持续预训练等多种策略，发现微调效果最佳，且小型模型性能可超越大型基线模型。研究发布了相关数据集和模型。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">大型语言模型（Large Language Models, LLMs）在各种医学自然语言处理（Natural Language Processing, NLP）任务中表现出色，但其巨大的计算需求常常限制了在实际医疗环境中的部署。本研究探讨了“小型”LLMs（约十亿参数）是否能在保持竞争力的准确性的同时有效执行医学任务。我们评估了来自三个主要系列——Llama-3、Gemma-3和Qwen3——的模型在命名实体识别（Named Entity Recognition）、关系抽取（Relation Extraction）、病例报告表填写（Case Report Form Filling）、问答（Question Answering）和论证挖掘（Argument Mining）等20个临床NLP任务上的表现。我们系统比较了一系列适应策略，包括推理时（少样本提示（few-shot prompting）、约束解码（constraint decoding））和训练时（监督微调（supervised fine-tuning）、持续预训练（continual pretraining））。微调被证明是最有效的方法，而少样本提示与约束解码的结合提供了强大的低资源替代方案。我们的结果表明，小型LLMs可以匹配甚至超越更大的基线模型，我们基于Qwen3-1.7B的最佳配置比Qwen3-32B平均得分高出+9.2分。我们发布了所有公开可用的意大利语医学NLP任务数据集的完整集合，以及我们表现最佳的模型。此外，我们发布了一个来自意大利医院急诊科的1.26亿词意大利语数据集，以及来自各种来源的1.75亿词数据，这些数据被我们用于持续预训练。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether "small" LLMs (around one billion parameters) can effectively perform medical tasks while maintaining competitive accuracy. We evaluate models from three major families-Llama-3, Gemma-3, and Qwen3-across 20 clinical NLP tasks among Named Entity Recognition, Relation Extraction, Case Report Form Filling, Question Answering, and Argument Mining. We systematically compare a range of adaptation strategies, both at inference time (few-shot prompting, constraint decoding) and at training time (supervised fine-tuning, continual pretraining). Fine-tuning emerges as the most effective approach, while the combination of few-shot prompting and constraint decoding offers strong lower-resource alternatives. Our results show that small LLMs can match or even surpass larger baselines, with our best configuration based on Qwen3-1.7B achieving an average score +9.2 points higher than Qwen3-32B. We release a comprehensive collection of all the publicly available Italian medical datasets for NLP tasks, together with our top-performing models. Furthermore, we release an Italian dataset of 126M words from the Emergency Department of an Italian Hospital, and 175M words from various sources that we used for continual pre-training.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Ferrazzi P</span>, <span class="author">Franzin M</span>, <span class="author">Lavelli A</span>, <span class="author">Magnini B</span></div>
                <div class="paper-keywords"><span class="keyword">小型大语言模型</span><span class="keyword">医学自然语言处理</span><span class="keyword">微调</span><span class="keyword">持续预训练</span><span class="keyword">约束解码</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17475v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17475v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>
            </div>
        </section>

        <section class="section">
            <div class="section-header 医疗数据集">
                <span class="section-icon" style="color: #047857;">◆</span>
                <h2 class="section-title">医疗数据集</h2>
                <span class="section-count">3 篇论文</span>
            </div>
            <div class="papers-grid">

        <article class="paper-card" data-category="医疗数据集">
            <div class="paper-header">
                <div class="paper-category">医疗数据集 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17531v1" target="_blank">Position: Evaluation of ECG Representations Must Be Fixed</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17531v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文主张修正当前12导联心电图表示学习的评估方法，提出应扩展至结构性心脏病和患者预后预测等临床目标，并指出在遵循最佳评估实践后，随机初始化的编码器性能可与先进预训练方法媲美，建议将其作为合理基线模型。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">这篇立场论文认为，当前12导联心电图（ECG）表示学习的基准测试实践必须修正，以确保进展可靠且与有临床意义的目标保持一致。该领域已主要集中于三个公共多标签基准（PTB-XL, CPSC2018, CSN），这些基准以心律失常和波形形态标签为主，尽管已知ECG编码了更广泛的临床信息。我们认为，下游评估应扩展到包括结构性心脏病和患者层面预测的评估，以及其他相关的、不断发展的ECG相关终点，作为临床目标。接着，我们概述了多标签、不平衡设置下的评估最佳实践，并表明当应用这些实践时，文献中关于哪种表示性能最佳的现有结论会发生改变。此外，我们证明了一个令人惊讶的结果：在许多任务上，随机初始化的编码器配合线性评估，其表现与最先进的预训练方法相当。这促使我们将随机编码器作为一个合理的基线模型。我们通过对三种代表性ECG预训练方法在六个评估设置（三个标准基准、一个结构性心脏病数据集、血流动力学推断和患者预测）中的实证评估来证实我们的观察。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">This position paper argues that current benchmarking practice in 12-lead ECG representation learning must be fixed to ensure progress is reliable and aligned with clinically meaningful objectives. The field has largely converged on three public multi-label benchmarks (PTB-XL, CPSC2018, CSN) dominated by arrhythmia and waveform-morphology labels, even though the ECG is known to encode substantially broader clinical information. We argue that downstream evaluation should expand to include an assessment of structural heart disease and patient-level forecasting, in addition to other evolving ECG-related endpoints, as relevant clinical targets. Next, we outline evaluation best practices for multi-label, imbalanced settings, and show that when they are applied, the literature's current conclusion about which representations perform best is altered. Furthermore, we demonstrate the surprising result that a randomly initialized encoder with linear evaluation matches state-of-the-art pre-training on many tasks. This motivates the use of a random encoder as a reasonable baseline model. We substantiate our observations with an empirical evaluation of three representative ECG pre-training approaches across six evaluation settings: the three standard benchmarks, a structural disease dataset, hemodynamic inference, and patient forecasting.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Berger Z</span>, <span class="author">Prakah-Asante D</span>, <span class="author">Guttag J</span>, <span class="author">Stultz CM</span></div>
                <div class="paper-keywords"><span class="keyword">心电图表示学习</span><span class="keyword">基准测试</span><span class="keyword">临床评估</span><span class="keyword">预训练模型</span><span class="keyword">随机编码器</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17531v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17531v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>

        <article class="paper-card" data-category="医疗数据集">
            <div class="paper-header">
                <div class="paper-category">医疗数据集 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17513v1" target="_blank">Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17513v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文通过构建新的产科病历数据集，系统评估了基于Transformer的监督模型与零样本大语言模型在临床文本段落分割任务上的表现。研究发现，监督模型在域内表现良好但跨域性能下降，而经过幻觉校正的零样本模型展现出更强的跨域鲁棒性，为医疗NLP在未充分研究领域的应用提供了新方向。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">临床自由文本笔记包含重要的患者信息。它们被组织成带标签的段落；识别这些段落已被证明有助于临床决策支持和下游NLP任务。在本文中，我们通过三个关键贡献推进临床段落分割研究。首先，我们整理了一个新的去标识化、带段落标签的产科笔记数据集，以补充如MIMIC-III等公共语料库所覆盖的医学领域，现有大多数分割方法都在此类语料上训练。其次，我们在精心整理的MIMIC-III子集（域内）和新产科数据集（域外）上，系统评估了基于Transformer的监督模型用于段落分割的性能。第三，我们首次对用于医学段落分割的监督模型与零样本大语言模型进行了直接比较。我们的结果表明，虽然监督模型在域内表现强劲，但其在域外的性能显著下降。相比之下，一旦校正了幻觉生成的段落标题，零样本模型展现出强大的域外适应能力。这些发现强调了开发特定领域临床资源的重要性，并凸显了零样本分割作为一个有前景的方向，可将医疗NLP应用于已充分研究的语料库之外，前提是幻觉得到适当管理。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">Clinical free-text notes contain vital patient information. They are structured into labelled sections; recognizing these sections has been shown to support clinical decision-making and downstream NLP tasks. In this paper, we advance clinical section segmentation through three key contributions. First, we curate a new de-identified, section-labeled obstetrics notes dataset, to supplement the medical domains covered in public corpora such as MIMIC-III, on which most existing segmentation approaches are trained. Second, we systematically evaluate transformer-based supervised models for section segmentation on a curated subset of MIMIC-III (in-domain), and on the new obstetrics dataset (out-of-domain). Third, we conduct the first head-to-head comparison of supervised models for medical section segmentation with zero-shot large language models. Our results show that while supervised models perform strongly in-domain, their performance drops substantially out-of-domain. In contrast, zero-shot models demonstrate robust out-of-domain adaptability once hallucinated section headers are corrected. These findings underscore the importance of developing domain-specific clinical resources and highlight zero-shot segmentation as a promising direction for applying healthcare NLP beyond well-studied corpora, as long as hallucinations are appropriately managed.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Karacan B</span>, <span class="author">Eugenio BD</span>, <span class="author">Thornton P</span></div>
                <div class="paper-keywords"><span class="keyword">临床文本分割</span><span class="keyword">领域适应</span><span class="keyword">零样本学习</span><span class="keyword">医学自然语言处理</span><span class="keyword">幻觉校正</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17513v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17513v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>

        <article class="paper-card" data-category="医疗数据集">
            <div class="paper-header">
                <div class="paper-category">医疗数据集 · cs.AI</div>
                <h3 class="paper-title"><a href="https://arxiv.org/abs/2602.17475v1" target="_blank">Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian</a></h3>
            </div>
            <div class="paper-meta">
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
                    2026-02-19
                </span>
                <span class="paper-meta-item">
                    <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>
                    arXiv:2602.17475v1
                </span>
            </div>
            <div class="paper-body">
                <p class="paper-summary">本文系统评估了约十亿参数的小型大语言模型在意大利语医学NLP任务上的表现。通过比较少样本提示、约束解码、监督微调和持续预训练等多种策略，发现微调效果最佳，且小型模型性能可超越大型基线模型。研究发布了相关数据集和模型。</p>
                
                <div class="abstract-section">
                    <button class="abstract-toggle" onclick="toggleAbstract(this)">
                        <span>查看摘要</span>
                        <span class="abstract-toggle-icon">▼</span>
                    </button>
                    <div class="abstract-content">
                        <div class="abstract-inner">
                            <div class="abstract-block">
                            <div class="abstract-label">中文摘要</div>
                            <div class="abstract-text">大型语言模型（Large Language Models, LLMs）在各种医学自然语言处理（Natural Language Processing, NLP）任务中表现出色，但其巨大的计算需求常常限制了在实际医疗环境中的部署。本研究探讨了“小型”LLMs（约十亿参数）是否能在保持竞争力的准确性的同时有效执行医学任务。我们评估了来自三个主要系列——Llama-3、Gemma-3和Qwen3——的模型在命名实体识别（Named Entity Recognition）、关系抽取（Relation Extraction）、病例报告表填写（Case Report Form Filling）、问答（Question Answering）和论证挖掘（Argument Mining）等20个临床NLP任务上的表现。我们系统比较了一系列适应策略，包括推理时（少样本提示（few-shot prompting）、约束解码（constraint decoding））和训练时（监督微调（supervised fine-tuning）、持续预训练（continual pretraining））。微调被证明是最有效的方法，而少样本提示与约束解码的结合提供了强大的低资源替代方案。我们的结果表明，小型LLMs可以匹配甚至超越更大的基线模型，我们基于Qwen3-1.7B的最佳配置比Qwen3-32B平均得分高出+9.2分。我们发布了所有公开可用的意大利语医学NLP任务数据集的完整集合，以及我们表现最佳的模型。此外，我们发布了一个来自意大利医院急诊科的1.26亿词意大利语数据集，以及来自各种来源的1.75亿词数据，这些数据被我们用于持续预训练。</div>
                        </div><div class="abstract-block">
                            <div class="abstract-label">英文摘要</div>
                            <div class="abstract-text">Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether "small" LLMs (around one billion parameters) can effectively perform medical tasks while maintaining competitive accuracy. We evaluate models from three major families-Llama-3, Gemma-3, and Qwen3-across 20 clinical NLP tasks among Named Entity Recognition, Relation Extraction, Case Report Form Filling, Question Answering, and Argument Mining. We systematically compare a range of adaptation strategies, both at inference time (few-shot prompting, constraint decoding) and at training time (supervised fine-tuning, continual pretraining). Fine-tuning emerges as the most effective approach, while the combination of few-shot prompting and constraint decoding offers strong lower-resource alternatives. Our results show that small LLMs can match or even surpass larger baselines, with our best configuration based on Qwen3-1.7B achieving an average score +9.2 points higher than Qwen3-32B. We release a comprehensive collection of all the publicly available Italian medical datasets for NLP tasks, together with our top-performing models. Furthermore, we release an Italian dataset of 126M words from the Emergency Department of an Italian Hospital, and 175M words from various sources that we used for continual pre-training.</div>
                        </div>
                        </div>
                    </div>
                </div>
        
            </div>
            <div class="paper-footer">
                <div class="paper-authors"><span class="author">Ferrazzi P</span>, <span class="author">Franzin M</span>, <span class="author">Lavelli A</span>, <span class="author">Magnini B</span></div>
                <div class="paper-keywords"><span class="keyword">小型大语言模型</span><span class="keyword">医学自然语言处理</span><span class="keyword">微调</span><span class="keyword">持续预训练</span><span class="keyword">约束解码</span></div>
            </div>
            <div class="paper-actions">
                <a href="https://arxiv.org/pdf/2602.17475v1" target="_blank" class="btn btn-primary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    PDF
                </a>
                <a href="https://arxiv.org/abs/2602.17475v1" target="_blank" class="btn btn-secondary">
                    <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><line x1="2" y1="12" x2="22" y2="12"></line><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"></path></svg>
                    arXiv
                </a>
            </div>
        </article>
            </div>
        </section>

        <section class="section">
            <div class="section-header 医疗智能体">
                <span class="section-icon" style="color: #7c3aed;">◆</span>
                <h2 class="section-title">医疗智能体</h2>
                <span class="section-count">0 篇论文</span>
            </div>
            <div class="papers-grid">
            </div>
        </section>
    </main>

    <footer class="footer">
        <p class="footer-text">生成于 2026-02-20 22:27 · 数据来源：arXiv.org</p>
    </footer>

    <script>
        // Filter functionality
        const statItems = document.querySelectorAll('.stat-item');
        const sections = document.querySelectorAll('.section');

        function filterPapers(filter) {
            // Update stat items
            statItems.forEach(item => {
                item.classList.toggle('active', item.dataset.filter === filter);
            });

            // Filter cards
            document.querySelectorAll('.paper-card').forEach(card => {
                if (filter === 'all' || card.dataset.category === filter) {
                    card.classList.remove('hidden');
                } else {
                    card.classList.add('hidden');
                }
            });

            // Show/hide sections
            sections.forEach(section => {
                const visibleCards = section.querySelectorAll('.paper-card:not(.hidden)');
                if (filter === 'all' || visibleCards.length > 0) {
                    section.classList.remove('hidden');
                } else {
                    section.classList.add('hidden');
                }
            });
        }

        statItems.forEach(item => {
            item.addEventListener('click', () => filterPapers(item.dataset.filter));
        });

        // Abstract toggle
        function toggleAbstract(btn) {
            const content = btn.nextElementSibling;
            const isExpanded = content.classList.contains('expanded');
            const textSpan = btn.querySelector('span:first-child');

            if (isExpanded) {
                content.classList.remove('expanded');
                btn.classList.remove('expanded');
                textSpan.textContent = '查看摘要';
            } else {
                content.classList.add('expanded');
                btn.classList.add('expanded');
                textSpan.textContent = '收起摘要';
            }
        }
    </script>
</body>
</html>
